# ğŸ”— PostWizz Link Scraping System - Complete Integration Guide

## ğŸ“‹ Overview

The Link Scraping System intelligently detects links in user text, scrapes relevant content, and enhances LinkedIn post generation with contextual insights. This system seamlessly integrates with PostWizz's existing AI orchestration and content generation pipeline.

## ğŸš€ Key Features

### âœ¨ Smart Link Detection
- **Real-time Detection**: Automatically identifies URLs as users type
- **Type Classification**: Categorizes links (GitHub, articles, websites, documentation, social)
- **Confidence Scoring**: Provides accuracy ratings for detected link types
- **Visual Indicators**: Shows detected links with type-specific icons and colors

### ğŸ” Intelligent Content Scraping
- **GitHub Integration**: Extracts repository data, README content, stars, forks, topics
- **Article Parsing**: Scrapes blog posts, Medium articles, dev.to content
- **Website Analysis**: Extracts titles, descriptions, main content from any website
- **Metadata Extraction**: Captures author, publish date, language, and other metadata

### ğŸ§  Enhanced AI Generation
- **Context Integration**: Combines user text with scraped insights
- **Smart Prompting**: Generates enhanced prompts for AI models
- **Fallback Handling**: Gracefully handles scraping failures
- **Content Optimization**: Maintains PostWizz's content quality standards

## ğŸ— System Architecture

### Backend Components

#### 1. **LinkScrapingTools.ts**
- `detectLinks()`: Real-time link detection and classification
- `scrapeUrls()`: Multi-URL content extraction with retry logic
- `generateWithScrapedContent()`: Enhanced content generation

#### 2. **Enhanced AIOrchestrator.ts**
- `processContentWithScrapedData()`: Integrated AI processing
- `generateScrapedContentPrompt()`: Context-aware prompt generation

#### 3. **Database Tables**
- `scraped_content`: Stores extracted content with metadata
- `link_cache`: Caches scraped data to avoid re-scraping
- `user_scraping_preferences`: User-specific scraping settings

### Frontend Components

#### 1. **LinkScrapingIndicator.tsx**
- Real-time link detection display
- Scraping progress visualization
- Expandable link details view
- Status indicators for each detected link

#### 2. **Enhanced PostAI.tsx**
- Integrated link scraping workflow
- Automatic tool selection based on detected links
- Enhanced user feedback and progress tracking

## ğŸ”§ MCP Tools Integration

### New Tools Added

#### 1. `detect-links`
```typescript
// Detects and classifies links in user text
{
  text: string,
  userId: string
}
```

#### 2. `scrape-urls`
```typescript
// Scrapes content from multiple URLs
{
  urls: string[],
  options?: ScrapeOptions,
  userId: string
}
```

#### 3. `generate-with-scraped-content`
```typescript
// Generates content with scraped data
{
  userText: string,
  scrapedData: any[],
  contentType?: string,
  userId: string
}
```

#### 4. `intelligent-content-with-links` (Main Integration)
```typescript
// Complete workflow: detect â†’ scrape â†’ generate
{
  content: string,
  userId: string,
  userContext?: UserContext
}
```

## ğŸ¯ User Experience Flow

### 1. **Content Input**
- User types text in PostAI textarea
- System automatically detects links in real-time
- LinkScrapingIndicator shows detected links with confidence scores

### 2. **Link Processing**
- When user clicks "Enhance & Preview"
- System shows progress: "ğŸ” Finding best context for you... Scraping X link(s)"
- Progress bar indicates scraping completion status

### 3. **Enhanced Generation**
- Scraped content is integrated with user text
- AI generates enhanced LinkedIn post with contextual insights
- Success message: "ğŸ”— Enhanced content generated with scraped insights!"

### 4. **Fallback Handling**
- If scraping fails, system falls back to standard generation
- No interruption to user workflow
- Transparent error handling with informative messages

## ğŸ“Š Database Schema

### Scraped Content Table
```sql
CREATE TABLE scraped_content (
    id UUID PRIMARY KEY,
    user_id UUID REFERENCES auth.users(id),
    url TEXT NOT NULL,
    type VARCHAR(50), -- 'github', 'article', 'website', etc.
    title TEXT,
    description TEXT,
    content TEXT,
    metadata JSONB,
    scraped_at TIMESTAMP,
    status VARCHAR(20) -- 'success', 'failed', 'processing'
);
```

### Link Cache Table
```sql
CREATE TABLE link_cache (
    url_hash VARCHAR(64) PRIMARY KEY,
    url TEXT NOT NULL,
    scraped_data JSONB,
    expires_at TIMESTAMP -- 24-hour cache
);
```

### User Preferences Table
```sql
CREATE TABLE user_scraping_preferences (
    user_id UUID PRIMARY KEY,
    auto_scrape BOOLEAN DEFAULT true,
    max_links_per_post INTEGER DEFAULT 3,
    preferred_content_types TEXT[],
    max_content_length INTEGER DEFAULT 5000
);
```

## ğŸ”’ Security & Performance

### Security Measures
- **URL Validation**: Strict URL format checking
- **Content Sanitization**: Removes malicious scripts and content
- **Rate Limiting**: Maximum 5 URLs per request
- **Timeout Protection**: 15-second timeout per scrape
- **User Isolation**: RLS policies ensure data privacy

### Performance Optimizations
- **Intelligent Caching**: 24-hour cache for scraped content
- **Parallel Processing**: Concurrent URL scraping
- **Content Limits**: Maximum 5KB per scraped page
- **Retry Logic**: 2 retry attempts with exponential backoff
- **Graceful Degradation**: Fallback to standard generation

## ğŸš€ Setup Instructions

### 1. Database Setup
```bash
# Run the database migration
psql -h your-supabase-host -d postgres -f mcp-server/scripts/setup-link-scraping-tables.sql
```

### 2. Environment Variables
```env
# Add to your .env file (if needed)
SCRAPING_TIMEOUT=15000
MAX_CONTENT_LENGTH=5000
CACHE_DURATION_HOURS=24
```

### 3. Dependencies Installation
```bash
cd mcp-server
bun install  # Installs cheerio, puppeteer, and @types/cheerio
```

### 4. Server Restart
```bash
cd mcp-server
bun dev  # Restart the MCP server
```

## ğŸ¨ UI Components

### LinkScrapingIndicator Features
- **Real-time Detection**: Updates as user types
- **Visual Feedback**: Color-coded link types with icons
- **Progress Tracking**: Shows scraping status for each URL
- **Expandable Details**: Click to view detected links
- **Status Messages**: Clear feedback on scraping progress

### PostAI Integration
- **Seamless Workflow**: No additional user actions required
- **Smart Tool Selection**: Automatically chooses enhanced generation when links detected
- **Progress Visualization**: Shows scraping progress during content generation
- **Enhanced Success Messages**: Indicates when scraped content was used

## ğŸ“ˆ Analytics & Monitoring

### Metrics Tracked
- Link detection accuracy
- Scraping success rates
- Content generation improvements
- User engagement with enhanced posts
- Cache hit rates

### Performance Monitoring
- Average scraping time per URL
- Memory usage during scraping
- Database query performance
- Error rates and types

## ğŸ”® Future Enhancements

### Planned Features
- **Advanced Scraping**: Support for JavaScript-heavy sites using Puppeteer
- **Content Summarization**: AI-powered content summarization for long articles
- **Link Validation**: Check for broken or inaccessible links
- **User Preferences**: Customizable scraping settings per user
- **Batch Processing**: Queue system for large-scale scraping

### Integration Opportunities
- **Calendar Integration**: Schedule posts with scraped content
- **Analytics Dashboard**: Track performance of posts with scraped content
- **Draft Management**: Save drafts with associated scraped data
- **Content Templates**: Pre-defined templates for different content types

## âœ… Testing Checklist

### Backend Testing
- [ ] Link detection accuracy across different URL types
- [ ] Scraping functionality for GitHub, articles, websites
- [ ] Database operations (insert, cache, retrieve)
- [ ] Error handling and fallback mechanisms
- [ ] Rate limiting and security measures

### Frontend Testing
- [ ] Real-time link detection in textarea
- [ ] Progress indicator functionality
- [ ] Enhanced content generation workflow
- [ ] Error handling and user feedback
- [ ] Responsive design across devices

### Integration Testing
- [ ] End-to-end workflow from detection to generation
- [ ] Fallback to standard generation when scraping fails
- [ ] Performance under various load conditions
- [ ] Cross-browser compatibility
- [ ] Mobile responsiveness

## ğŸ‰ Success Metrics

The Link Scraping System is successfully integrated when:
- âœ… Links are detected automatically as users type
- âœ… Scraping progress is clearly visible to users
- âœ… Enhanced content generation works with scraped insights
- âœ… System gracefully handles failures with fallbacks
- âœ… Database operations are secure and performant
- âœ… User experience remains smooth and intuitive

---

**ğŸš€ The PostWizz Link Scraping System is now ready to enhance your LinkedIn content creation with intelligent web scraping capabilities!**
